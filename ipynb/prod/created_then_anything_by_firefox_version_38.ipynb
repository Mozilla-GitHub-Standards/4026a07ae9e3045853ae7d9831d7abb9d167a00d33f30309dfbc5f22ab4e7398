{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'created' then did 'anything' - Firefox v38"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "COHORT_QUERY = \"SELECT C4 FROM %s WHERE C5 = 'account.created' AND C1 = 'Firefox' AND C2 = '38'\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "REST_QUERY = \"SELECT C4 FROM %s\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "TITLE = \"'created' then did 'anything' - Firefox v38\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "EVENT_STORAGE = \"s3n://net-mozaws-prod-us-west-2-pipeline-analysis/fxa-retention/data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import date, timedelta, datetime\n",
    "import pandas\n",
    "\n",
    "IN_IPYTHON = True\n",
    "try:\n",
    "    __IPYTHON__\n",
    "except NameError:\n",
    "    IN_IPYTHON = False\n",
    "\n",
    "today = date.today()\n",
    "# today = datetime.strptime('2015-11-08', '%Y-%m-%d').date()\n",
    "last_monday = today - timedelta(days=-today.weekday(), weeks=1)\n",
    "\n",
    "WEEK_RANGE = pandas.date_range(end=last_monday, periods=15, freq='W-MON')\n",
    "WEEKS = WEEK_RANGE.map(lambda x: x.strftime('%Y-%m-%d'))\n",
    "\n",
    "if not IN_IPYTHON:\n",
    "    EVENT_STORAGE = os.path.join(os.path.dirname(os.path.abspath(__file__)), '..', '..', 'tools', 'out')\n",
    "\n",
    "OUT_DATA = []\n",
    "VOLUME_DATA = []\n",
    "\n",
    "for v in range(0, len(WEEKS)):\n",
    "    VOLUME_DATA.append([0] * len(WEEKS))\n",
    "\n",
    "for x in range(0, len(WEEKS)):\n",
    "    OUT_DATA.append([0] * len(WEEKS))\n",
    "\n",
    "def week_file(storage, week):\n",
    "    return os.path.join(storage, 'events-' + week + '.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas, os, sys\n",
    "# Only initialize Spark if testing locally\n",
    "# Otherwise it should be already running within Spark\n",
    "try:\n",
    "    from pyspark import SparkContext\n",
    "except ImportError:\n",
    "    import dev_env\n",
    "\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SQLContext, Row\n",
    "\n",
    "IN_IPYTHON = True\n",
    "\n",
    "try:\n",
    "    __IPYTHON__\n",
    "except NameError:\n",
    "    IN_IPYTHON = False\n",
    "    sc = SparkContext('local')\n",
    "    sys.path.append(os.path.realpath(os.curdir))\n",
    "    from ipynb_generators.parts.weeks import WEEKS, WEEK_RANGE, OUT_DATA, VOLUME_DATA, EVENT_STORAGE, week_file\n",
    "    COHORT_QUERY = \"SELECT C4 FROM %s WHERE C5 = 'account.created'\"\n",
    "    REST_QUERY = \"SELECT C4 FROM %s\"\n",
    "    print \"Not in IPython, creating SparkContext manually, using fake data!\"\n",
    "\n",
    "# sc will be global in IPython\n",
    "sqlContext = SQLContext(sc)\n",
    "\n",
    "for x in range(0, len(WEEKS)):\n",
    "    saved_uids = None\n",
    "    saved_uids_count = None\n",
    "\n",
    "    idx = 0\n",
    "    for week in WEEKS[x:]:\n",
    "        df = sqlContext.load(source='com.databricks.spark.csv', header='false', path=week_file(EVENT_STORAGE, week))\n",
    "        table_name = 'week' + week.replace('-', '_')\n",
    "        df.registerTempTable(table_name)\n",
    "\n",
    "        if not saved_uids:\n",
    "            cohort_events = sqlContext.sql(COHORT_QUERY % table_name)\n",
    "            new_uids = cohort_events.map(lambda p: p.C4).distinct()\n",
    "\n",
    "            saved_uids = new_uids\n",
    "            saved_uids_count = int(new_uids.count())\n",
    "            VOLUME_DATA[x][idx] = saved_uids_count\n",
    "            OUT_DATA[x][idx] = 100\n",
    "        else:\n",
    "            secondary_events = sqlContext.sql(REST_QUERY % table_name)\n",
    "            new_uids_created_events = secondary_events.map(lambda p: p.C4).distinct()\n",
    "\n",
    "            retention_uids = saved_uids.intersection(new_uids_created_events)\n",
    "            if saved_uids_count > 0:\n",
    "                percentage = int((float(retention_uids.count()) / float(saved_uids_count)) * 100)\n",
    "            else:\n",
    "                percentage = 0\n",
    "            OUT_DATA[x][idx] = percentage\n",
    "            VOLUME_DATA[x][idx] = int(retention_uids.count())\n",
    "        idx += 1\n",
    "\n",
    "DATA_FRAME = pandas.DataFrame(OUT_DATA, index=WEEK_RANGE, columns=range(0, len(WEEKS)))\n",
    "VOLUME_DATA_FRAME = pandas.DataFrame(VOLUME_DATA, index=WEEK_RANGE, columns=range(0, len(WEEKS)))\n",
    "\n",
    "if not IN_IPYTHON:\n",
    "    print DATA_FRAME\n",
    "    print VOLUME_DATA_FRAME\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "IN_IPYTHON = True\n",
    "try:\n",
    "    __IPYTHON__\n",
    "except NameError:\n",
    "    IN_IPYTHON = False\n",
    "\n",
    "if IN_IPYTHON:\n",
    "    if \"DATA_FRAME\" in locals():\n",
    "        seaborn.set(style='white')\n",
    "        plt.figure(figsize=(16, 12))\n",
    "        plt.title(TITLE, { 'fontsize': 26 })\n",
    "        seaborn.heatmap(DATA_FRAME, annot=True, fmt='d', yticklabels=WEEKS, xticklabels=range(0, len(WEEKS)))\n",
    "        # Rotate labels\n",
    "        locs, labels = plt.yticks()\n",
    "        plt.setp(labels, rotation=0)\n",
    "        # Set axis font\n",
    "        font = {\n",
    "            'weight': 'bold',\n",
    "            'size': 22\n",
    "        }\n",
    "        # Label axis\n",
    "        plt.ylabel('Cohort Starting Week', **font)\n",
    "        plt.xlabel('Retention Weeks', **font)\n",
    "\n",
    "        print VOLUME_DATA_FRAME\n",
    "\n",
    "    if \"WEEKLY_DATA\" in locals():\n",
    "            print WEEKLY_DATA\n",
    "            fig = plt.figure(figsize=(16, 12))\n",
    "\n",
    "            plt.title(TITLE, { 'fontsize': 26 })\n",
    "            for item in WEEKLY_DATA:\n",
    "                val = WEEKLY_DATA[item]\n",
    "                plt.plot(val)\n",
    "                ax = fig.add_subplot(111)\n",
    "                for x,y in zip(range(15), val):\n",
    "                    ax.annotate('%s' %y, xy=(x,y), size=15)\n",
    "\n",
    "            plt.ylabel('Percentage')\n",
    "            plt.setp(plt.gca().get_xticklabels(), rotation=45, horizontalalignment='right')\n",
    "            plt.xticks(range(15), WEEKS)\n",
    "            plt.legend(WEEKLY_DATA.keys(), loc='lower left', prop={'size': 16})\n",
    "\n",
    "\n",
    "            plt.ylim(-10, 110)\n",
    "            plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "language": "python"
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
