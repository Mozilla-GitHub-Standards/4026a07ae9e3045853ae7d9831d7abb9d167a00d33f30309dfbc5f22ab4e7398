{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "User Retention using accounts.signed events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import date, timedelta\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# Only initialize Spark if testing locally\n",
    "# Otherwise it should be already running within Spark\n",
    "if os.environ.has_key('FXA_SPARK_TESTING'):\n",
    "    import spark_env\n",
    "\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SQLContext, Row\n",
    "\n",
    "try:\n",
    "    __IPYTHON__\n",
    "except NameError:\n",
    "    sc = SparkContext('local')\n",
    "    print \"Not in IPython, creating SparkContext manually\"\n",
    "\n",
    "\n",
    "def week_file(week):\n",
    "    return '../tools/out/events-' + week + '.csv'\n",
    "\n",
    "# sc will be global in IPython\n",
    "sqlContext = SQLContext(sc)\n",
    "today = date.today()\n",
    "last_monday = today - timedelta(days=-today.weekday(), weeks=1)\n",
    "week_range = pd.date_range(end=last_monday, periods=12, freq='W-MON')\n",
    "\n",
    "WEEKS = week_range.map(lambda x: x.strftime('%Y-%m-%d'))\n",
    "\n",
    "out_data = []\n",
    "for x in range(0, len(WEEKS)):\n",
    "    out_data.append([0] * len(WEEKS))\n",
    "\n",
    "for x in range(0, len(WEEKS)):\n",
    "    saved_uids = None\n",
    "    saved_uids_count = None\n",
    "\n",
    "    idx = 0\n",
    "    for week in WEEKS[x:]:\n",
    "        df = sqlContext.load(source='com.databricks.spark.csv', header='true', path=week_file(week))\n",
    "        table_name = 'week' + week.replace('-', '_')\n",
    "        df.registerAsTable(table_name)\n",
    "\n",
    "        signed_events = sqlContext.sql(\"SELECT uid FROM \" + table_name + \" WHERE event = 'account.signed'\")\n",
    "\n",
    "        new_uids = signed_events.map(lambda p: p.uid).distinct()\n",
    "\n",
    "        if not saved_uids:\n",
    "            saved_uids = new_uids\n",
    "            saved_uids_count = int(new_uids.count())\n",
    "            out_data[x][idx] = 100\n",
    "        else:\n",
    "            retention_uids = saved_uids.intersection(new_uids)\n",
    "            if saved_uids_count > 0:\n",
    "                percentage = int((float(retention_uids.count()) / float(saved_uids_count)) * 100)\n",
    "            else:\n",
    "                percentage = 0\n",
    "            out_data[x][idx] = percentage\n",
    "        idx += 1\n",
    "\n",
    "df = pd.DataFrame(out_data, index=week_range, columns=WEEKS)\n",
    "sns.set(style='white')\n",
    "plt.figure(figsize=(14, 12))\n",
    "plt.title('User Retention based on \"account.signed\"')\n",
    "sns.heatmap(df, annot=True, fmt='d', yticklabels=week_range, xticklabels=range(0, 12))\n",
    "# Rotate labels\n",
    "locs, labels = plt.yticks()\n",
    "plt.setp(labels, rotation=0)\n",
    "# Set axis font\n",
    "font = {\n",
    "    'weight': 'bold',\n",
    "    'size': 22\n",
    "}\n",
    "# Label axis\n",
    "plt.ylabel('Starting Week', **font)\n",
    "plt.xlabel('Retention Weeks', **font)\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language": "python"
 },
 "nbformat": 4,
 "nbformat_minor": 0
}